# -*- coding: utf-8 -*-
"""TFRecords

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xmWPW_8jnfxgYAqYQ8NzfOkneDNw-He8
"""

#TFRecords.py

# Commented out IPython magic to ensure Python compatibility.
from __future__ import absolute_import, division, print_function, unicode_literals

import tensorflow as tf
from tensorflow.keras.utils import get_file

import numpy as np
import IPython.display as display

import argparse
import os
import sys

import tarfile
from six.moves import cPickle as pickle
from six.moves import xrange
from datetime import datetime



CIFAR_FILENAME = 'cifar-10-python.tar.gz'
CIFAR_DOWNLOAD_URL = 'https://www.cs.toronto.edu/~kriz/' + CIFAR_FILENAME
CIFAR_LOCAL_FOLDER = 'cifar-10-batches-py'


data_dir = './tfrecords_data'


def download_and_extract(data_dir):
  # download CIFAR-10 if not already downloaded.
  path = get_file(
      fname = CIFAR_FILENAME,
      origin=CIFAR_DOWNLOAD_URL,
      untar=True,
      file_hash='6d958be074577803d12ecdefd02955f39262c83c16fe9348329d7fe0b5c001ce',
      cache_subdir = data_dir)
  #tarfile.open(os.path.join(data_dir, CIFAR_FILENAME),
  #             'r:gz').extractall(data_dir)
  
  
  
def _int64_feature(value):
  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))


def _bytes_feature(value):
  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))


def _float_feature(value):
  """Returns a float_list from a float / double."""
  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))



def _get_file_names():
  """Returns the file names expected to exist in the input_dir."""
  file_names = {}
  file_names['train'] = ['data_batch_%d' % i for i in xrange(1, 6)]
  #file_names['validation'] = ['data_batch_5']
  file_names['test'] = ['test_batch']
  return file_names


def read_pickle_from_file(filename):
  with tf.io.gfile.GFile(filename, 'rb') as f:
    if sys.version_info >= (3, 0):
      data_dict = pickle.load(f, encoding='bytes')
    else:
      data_dict = pickle.load(f)
  return data_dict


def convert_to_tfrecord(input_files, output_file):
  """Converts a file to TFRecords."""
  print('Generating %s' % output_file)
  with tf.io.TFRecordWriter(output_file) as record_writer:
    for input_file in input_files:
      data_dict = read_pickle_from_file(input_file)
      data = data_dict[b'data']
      labels = data_dict[b'labels']
      num_entries_in_batch = len(labels)
      for i in range(num_entries_in_batch):
        example = tf.train.Example(features=tf.train.Features(
            feature={
                'image': _bytes_feature(data[i].tobytes()),
                #'label': _int64_feature(labels[i])
                'label': _float_feature(labels[i])
            }))
        record_writer.write(example.SerializeToString())
        
        
def gen_tfrecords(datasetname = "CIFAR10"):
  if not os.path.isdir(data_dir):
    os.mkdir(data_dir)
  if datasetname == "CIFAR10":
    download_and_extract(data_dir)
    file_names = _get_file_names()
    input_dir = os.path.join(data_dir, CIFAR_LOCAL_FOLDER)
  tfrecords_list = []
  for mode, files in file_names.items():
    input_files = [os.path.join(input_dir, f) for f in files]
    output_file = os.path.join(data_dir, mode + '.tfrecords')
    try:
      os.remove(output_file)
    except OSError:
      pass
    # Convert to tf.train.Example and write the to TFRecords.
    convert_to_tfrecord(input_files, output_file)
    tfrecords_list.append(output_file)
  return tfrecords_list
  
        
def parser(serialized_example):
  """Parses a single tf.Example into image and label tensors."""
  # Dimensions of the images in the CIFAR-10 dataset.
  # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the input format.
  DEPTH = 3
  HEIGHT = 32
  WIDTH = 32
  num_classes = 10
  features = tf.io.parse_single_example(
    serialized_example,
    features={
      'image': tf.io.FixedLenFeature([], tf.string),
      #'label': tf.io.FixedLenFeature([], tf.int64),
      'label': tf.io.FixedLenFeature([], tf.float32),
      })
  image = tf.decode_raw(features['image'], tf.uint8)
  image.set_shape([DEPTH * HEIGHT * WIDTH])

  # Reshape from [depth * height * width] to [depth, height, width].
  image = tf.cast(
    tf.transpose(tf.reshape(image, [DEPTH, HEIGHT, WIDTH]), [1, 2, 0]),
    tf.float32)
  label = tf.cast(features['label'], tf.int64)
  #label = tf.cast(features['label'], tf.float32)
  label = tf.one_hot(indices=label, depth=num_classes)
  return image, label


def convert_to_tfrecords(X_data, Y_data):
  """Converts a given dataset to TFRecords."""
  output_file = output_file = os.path.join(data_dir, 'data' + str(datetime.utcnow()) +'.tfrecords')
  print('Generating %s' % output_file)
  with tf.io.TFRecordWriter(output_file) as record_writer:
    data = X_data
    labels = Y_data
    num_entries_in_batch = len(labels)
    for i in range(num_entries_in_batch):
      example = tf.train.Example(features=tf.train.Features(
        feature={
          'image': _bytes_feature(data[i].tobytes()),
          #'label': _int64_feature(labels[i])
          'label': _float_feature(labels[i])
          }))
    record_writer.write(example.SerializeToString())
  return output_file